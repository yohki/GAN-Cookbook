{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GAN Cookbook: DCGAN (2)",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yohki/GAN-Cookbook/blob/master/GAN_Cookbook_DCGAN_(2).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1zg0H49VtWbm",
        "colab_type": "text"
      },
      "source": [
        "# Generator\n",
        "\n",
        "今までのGANとDCGANを切り替えて使えるようにしているのでコードが多少長くなっている。DCGANのモデルは34〜54行目。\n",
        "\n",
        "![alt text](https://drive.google.com/uc?id=1C2Z03je-tWywYQMhAXfqzTt6SJGvDwLQ)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "798BZsTStXzC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cb1997f0-ca75-4025-9d63-0820de821bcd"
      },
      "source": [
        "#!/usr/bin/env python3\n",
        "import sys\n",
        "import numpy as np\n",
        "from keras.layers import Dense, Reshape, Input, BatchNormalization\n",
        "from keras.layers.core import Activation\n",
        "from keras.layers.convolutional import UpSampling2D, Convolution2D, MaxPooling2D,Deconvolution2D\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.models import Sequential, Model\n",
        "from keras.optimizers import Adam, SGD, Nadam,Adamax\n",
        "from keras import initializers\n",
        "from keras.utils import plot_model\n",
        "\n",
        "class Generator(object):\n",
        "    def __init__(self, width = 28, height= 28, channels = 1, latent_size=100, model_type = 'simple'):\n",
        "        \n",
        "        self.W = width\n",
        "        self.H = height\n",
        "        self.C = channels\n",
        "        self.LATENT_SPACE_SIZE = latent_size\n",
        "        self.latent_space = np.random.normal(0,1,(self.LATENT_SPACE_SIZE,))\n",
        "\n",
        "        if model_type=='simple':\n",
        "            self.Generator = self.model()\n",
        "            self.OPTIMIZER = Adam(lr=0.0002, decay=8e-9)\n",
        "            self.Generator.compile(loss='binary_crossentropy', optimizer=self.OPTIMIZER)\n",
        "        elif model_type=='DCGAN':\n",
        "            self.Generator = self.dc_model()\n",
        "            self.OPTIMIZER = Adam(lr=1e-4, beta_1=0.2)\n",
        "            self.Generator.compile(loss='binary_crossentropy', optimizer=self.OPTIMIZER,metrics=['accuracy'])\n",
        "        self.save_model()\n",
        "        self.summary()\n",
        "        \n",
        "    # DCGANのモデル\n",
        "    def dc_model(self):\n",
        "\n",
        "        model = Sequential()\n",
        "\n",
        "        model.add(Dense(256*8*8,activation=LeakyReLU(0.2), input_dim=self.LATENT_SPACE_SIZE))\n",
        "        model.add(BatchNormalization())\n",
        "\n",
        "        model.add(Reshape((8, 8, 256)))\n",
        "        model.add(UpSampling2D())\n",
        "\n",
        "        model.add(Convolution2D(128, 5, 5, border_mode='same',activation=LeakyReLU(0.2)))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(UpSampling2D())\n",
        "\n",
        "        model.add(Convolution2D(64, 5, 5, border_mode='same',activation=LeakyReLU(0.2)))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(UpSampling2D())\n",
        "\n",
        "        model.add(Convolution2D(self.C, 5, 5, border_mode='same', activation='tanh'))\n",
        "        \n",
        "        return model\n",
        "\n",
        "    # 普通のGANモデル\n",
        "    def model(self, block_starting_size=128,num_blocks=4):\n",
        "        model = Sequential()\n",
        "        \n",
        "        block_size = block_starting_size \n",
        "        model.add(Dense(block_size, input_shape=(self.LATENT_SPACE_SIZE,)))\n",
        "        model.add(LeakyReLU(alpha=0.2))\n",
        "        model.add(BatchNormalization(momentum=0.8))\n",
        "\n",
        "        for i in range(num_blocks-1):\n",
        "            block_size = block_size * 2\n",
        "            model.add(Dense(block_size))\n",
        "            model.add(LeakyReLU(alpha=0.2))\n",
        "            model.add(BatchNormalization(momentum=0.8))\n",
        "\n",
        "        model.add(Dense(self.W * self.H * self.C, activation='tanh'))\n",
        "        model.add(Reshape((self.W, self.H, self.C)))\n",
        "        \n",
        "        return model\n",
        "\n",
        "    def summary(self):\n",
        "        return self.Generator.summary()\n",
        "\n",
        "    def save_model(self):\n",
        "        plot_model(self.Generator.model, to_file='DCGAN/Generator_Model.png')\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S8mQkdTweMt7",
        "colab_type": "text"
      },
      "source": [
        "* l.38:最初の入力は16384個のノイズ。 \n",
        "* l.41: それを8x8x256の3次元ボリュームに変換。\n",
        "* l.42: 縦横2倍にアップスケールして16x16x256にする。\n",
        "* l.44: 16x16x256の入力に対して、5x5x256のフィルタを使って畳み込みを行い、16x16の特徴マップを128個生成している。 \n",
        "* 通常畳み込みを行うと出力サイズが小さくなるが、`border_mode='same'`は周りを0で埋めることでサイズを変えずに畳み込みを行うことができる（ゼロパディング）。\n",
        "\n",
        "![alt text](https://deepage.net/img/convolutional_neural_network/zero_padding.jpg\n",
        ")\n",
        "\n",
        "* l.46: 再び縦横2倍にアップスケールしてサイズを32x32x128にする。\n",
        "* l.48: 2回目の畳み込み。32x32x128の入力に対してフィルタサイズが5x5x128、フィルタ数が64なので出力は32x32x64になる。\n",
        "* l.50: 再度アップサンプリング。これでサイズが64x64x64になる。\n",
        "* l.52: 最終画像として出力するために畳み込みを行う。入力サイズ=64x64x64、フィルタサイズ=5x5x64、フィルタ数=3、出力サイズ=64x64x3。これで64x64のRGB画像ができる。\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wkXUW-Cipf_G",
        "colab_type": "text"
      },
      "source": [
        "# Discriminator\n",
        "\n",
        "![alt text](https://drive.google.com/uc?id=1hP6PuCuwHefJhvbnTmJ5t1qyZqM17f5B)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4rFeqkg6pfE2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!/usr/bin/env python3\n",
        "import sys\n",
        "import numpy as np\n",
        "from keras.layers import Input, Dense, Reshape, Flatten, Dropout, BatchNormalization, Lambda, concatenate\n",
        "from keras.layers.core import Activation\n",
        "from keras.layers.convolutional import Convolution2D\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.models import Sequential, Model\n",
        "from keras.optimizers import Adam, SGD,Nadam, Adamax\n",
        "import keras.backend as K\n",
        "from keras.utils import plot_model\n",
        "\n",
        "\n",
        "class Discriminator(object):\n",
        "    def __init__(self, width = 28, height= 28, channels = 1, latent_size=100,model_type = 'simple'):\n",
        "        self.W = width\n",
        "        self.H = height\n",
        "        self.C = channels\n",
        "        self.CAPACITY = width*height*channels\n",
        "        self.SHAPE = (width,height,channels)\n",
        "        \n",
        "        if model_type=='simple':\n",
        "            self.Discriminator = self.model()\n",
        "            self.OPTIMIZER = Adam(lr=0.0002, decay=8e-9)\n",
        "            self.Discriminator.compile(loss='binary_crossentropy', optimizer=self.OPTIMIZER, metrics=['accuracy'] )\n",
        "        elif model_type=='DCGAN':\n",
        "            self.Discriminator = self.dc_model()\n",
        "            self.OPTIMIZER = Adam(lr=1e-4, beta_1=0.2)\n",
        "            self.Discriminator.compile(loss='binary_crossentropy', optimizer=self.OPTIMIZER, metrics=['accuracy'] )\n",
        "\n",
        "        self.save_model()\n",
        "        self.summary()\n",
        "\n",
        "    def dc_model(self):\n",
        "        model = Sequential()\n",
        "        model.add(Convolution2D(64, 5, 5, subsample=(2,2), input_shape=(self.W,self.H,self.C), border_mode='same',activation=LeakyReLU(alpha=0.2)))\n",
        "        model.add(Dropout(0.3))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Convolution2D(128, 5, 5, subsample=(2,2), border_mode='same',activation=LeakyReLU(alpha=0.2)))\n",
        "        model.add(Dropout(0.3))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(1, activation='sigmoid'))\n",
        "        return model\n",
        "\n",
        "    def model(self):\n",
        "        model = Sequential()\n",
        "        model.add(Flatten(input_shape=self.SHAPE))\n",
        "        model.add(Dense(self.CAPACITY, input_shape=self.SHAPE))\n",
        "        model.add(LeakyReLU(alpha=0.2))\n",
        "        model.add(Dense(int(self.CAPACITY/2)))\n",
        "        model.add(LeakyReLU(alpha=0.2))\n",
        "        model.add(Dense(1, activation='sigmoid'))\n",
        "        return model\n",
        "\n",
        "    def summary(self):\n",
        "        return self.Discriminator.summary()\n",
        "\n",
        "    def save_model(self):\n",
        "        plot_model(self.Discriminator.model, to_file='DCGAN/Discriminator_Model.png')\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rn9aG_4SXLEa",
        "colab_type": "text"
      },
      "source": [
        "- `Convolution2D`の`subsample=(2,2)`はストライドのことと思われる。`Conv2D(... stride=(2,2))`と同等で、これによりダウンサンプリングが行われる。\n",
        "- 2層目の`Convolution2D`では`subsample=(2,2)`としておきつつ、`border_mode='same'`として出力サイズを同じに保っているがなぜ？\n",
        "- l.38, 41: Batch Normalizationは入れた方がいい説とそうでない説がある。（→[KerasでDCGAN書く](https://qiita.com/t-ae/items/236457c29ba85a7579d5)）\n",
        "- l.37, 40: `Dropout()`は一定割合で結合を切ってやることで過学習を防ぐ処理。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yp_55kIeq1kE",
        "colab_type": "text"
      },
      "source": [
        "# GAN\n",
        "\n",
        "前の章で使っていたものと同じ。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IavDME86pvlK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!/usr/bin/env python3\n",
        "import sys\n",
        "import numpy as np\n",
        "from keras.models import Sequential, Model\n",
        "from keras.optimizers import Adam, SGD\n",
        "from keras.utils import plot_model\n",
        "\n",
        "class GAN(object):\n",
        "    def __init__(self,discriminator,generator):\n",
        "        self.OPTIMIZER = SGD(lr=2e-4,nesterov=True)\n",
        "        self.Generator = generator\n",
        "\n",
        "        self.Discriminator = discriminator\n",
        "        self.Discriminator.trainable = False\n",
        "        \n",
        "        self.gan_model = self.model()\n",
        "        self.gan_model.compile(loss='binary_crossentropy', optimizer=self.OPTIMIZER)\n",
        "        self.save_model()\n",
        "        self.summary()\n",
        "\n",
        "    def model(self):\n",
        "        model = Sequential()\n",
        "        model.add(self.Generator)\n",
        "        model.add(self.Discriminator)\n",
        "        return model\n",
        "\n",
        "    def summary(self):\n",
        "        return self.gan_model.summary()\n",
        "\n",
        "    def save_model(self):\n",
        "        plot_model(self.gan_model.model, to_file='DCGAN/GAN_Model.png')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pOMUK9UDsF2O",
        "colab_type": "text"
      },
      "source": [
        "# Trainer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N2QMfypkq69V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.datasets import mnist\n",
        "from random import randint\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from copy import deepcopy\n",
        "import time\n",
        "import datetime\n",
        "\n",
        "class Trainer:\n",
        "    def __init__(self, width = 28, height= 28, channels = 1, latent_size=100, epochs =50000, batch=32, checkpoint=50,model_type=-1,data_path = ''):\n",
        "        self.W = width\n",
        "        self.H = height\n",
        "        self.C = channels\n",
        "        self.EPOCHS = epochs\n",
        "        self.BATCH = batch\n",
        "        self.CHECKPOINT = checkpoint\n",
        "        self.model_type=model_type\n",
        "\n",
        "        self.LATENT_SPACE_SIZE = latent_size\n",
        "\n",
        "        self.generator = Generator(height=self.H, width=self.W, channels=self.C, latent_size=self.LATENT_SPACE_SIZE,model_type = 'DCGAN')\n",
        "        self.discriminator = Discriminator(height=self.H, width=self.W, channels=self.C,model_type = 'DCGAN')\n",
        "        self.gan = GAN(generator=self.generator.Generator, discriminator=self.discriminator.Discriminator)\n",
        "\n",
        "        #self.load_MNIST()\n",
        "        self.load_npy(data_path)\n",
        "\n",
        "    def load_npy(self,npy_path):\n",
        "        self.X_train = np.load(npy_path)\n",
        "        self.X_train = self.X_train[:int(0.25*float(len(self.X_train)))]\n",
        "        self.X_train = (self.X_train.astype(np.float32) - 127.5)/127.5\n",
        "        self.X_train = np.expand_dims(self.X_train, axis=3)\n",
        "        return\n",
        "\n",
        "    def load_MNIST(self,model_type=3):\n",
        "        allowed_types = [-1,0,1,2,3,4,5,6,7,8,9]\n",
        "        if self.model_type not in allowed_types:\n",
        "            print('ERROR: Only Integer Values from -1 to 9 are allowed')\n",
        "\n",
        "        (self.X_train, self.Y_train), (_, _) = mnist.load_data()\n",
        "        if self.model_type!=-1:\n",
        "            self.X_train = self.X_train[np.where(self.Y_train==int(self.model_type))[0]]\n",
        "        \n",
        "        # Rescale -1 to 1\n",
        "        # Find Normalize Function from CV Class  \n",
        "        self.X_train = ( np.float32(self.X_train) - 127.5) / 127.5\n",
        "        self.X_train = np.expand_dims(self.X_train, axis=3)\n",
        "        return\n",
        "\n",
        "    def train(self):\n",
        "        for e in range(self.EPOCHS):\n",
        "            e_start = time.time()\n",
        "            b = 0\n",
        "            X_train_temp = deepcopy(self.X_train)\n",
        "            while self.BATCH < len(X_train_temp):\n",
        "                b_start = time.time()\n",
        "                # Keep track of Batches\n",
        "                b=b+1\n",
        "\n",
        "                # Train Discriminator\n",
        "                # Make the training batch for this model be half real, half noise\n",
        "                # Grab Real Images for this training batch\n",
        "                if self.flipCoin():\n",
        "                    count_real_images = int(self.BATCH)\n",
        "                    starting_index = randint(0, (len(X_train_temp)-count_real_images))\n",
        "                    real_images_raw = X_train_temp[ starting_index : (starting_index + count_real_images) ]\n",
        "                    #self.plot_check_batch(b,real_images_raw)\n",
        "                    # Delete the images used until we have none left\n",
        "                    X_train_temp = np.delete(X_train_temp,range(starting_index,(starting_index + count_real_images)),0)\n",
        "                    x_batch = real_images_raw.reshape( count_real_images, self.W, self.H, self.C )\n",
        "                    y_batch = np.ones([count_real_images,1])\n",
        "                else:\n",
        "                    # Grab Generated Images for this training batch\n",
        "                    latent_space_samples = self.sample_latent_space(self.BATCH)\n",
        "                    x_batch = self.generator.Generator.predict(latent_space_samples)\n",
        "                    y_batch = np.zeros([self.BATCH,1])\n",
        "\n",
        "                # Now, train the discriminator with this batch\n",
        "                discriminator_loss = self.discriminator.Discriminator.train_on_batch(x_batch,y_batch)[0]\n",
        "            \n",
        "                # In practice, flipping the label when training the generator improves convergence\n",
        "                if self.flipCoin(chance=0.9):\n",
        "                    y_generated_labels = np.ones([self.BATCH,1])\n",
        "                else:\n",
        "                    y_generated_labels = np.zeros([self.BATCH,1])\n",
        "                x_latent_space_samples = self.sample_latent_space(self.BATCH)\n",
        "                generator_loss = self.gan.gan_model.train_on_batch(x_latent_space_samples,y_generated_labels)\n",
        "    \n",
        "                b_elapsed = time.time() - b_start\n",
        "                if b % self.CHECKPOINT == 0:\n",
        "                    print('Batch: ' + str(int(b)) + \n",
        "                       ', [Discriminator :: Loss: ' + str(discriminator_loss) + \n",
        "                       '], [ Generator :: Loss: '+str(generator_loss) + \n",
        "                       '], {0}s'.format(b_elapsed))\n",
        "                    label = str(e)+'_'+str(b)\n",
        "                    self.plot_checkpoint(label)\n",
        "            e_elapsed = time.time() - e_start\n",
        "            print ('Epoch: '+str(int(e)) + \n",
        "                   ', [Discriminator :: Loss: ' + str(discriminator_loss) + \n",
        "                   '], [ Generator :: Loss: ' + str(generator_loss) + \n",
        "                   '], {0}s'.format(e_elapsed))\n",
        "                        \n",
        "            if e % self.CHECKPOINT == 0 :\n",
        "                self.plot_checkpoint(e)\n",
        "        return\n",
        "\n",
        "    def flipCoin(self,chance=0.5):\n",
        "        return np.random.binomial(1, chance)\n",
        "\n",
        "    def sample_latent_space(self, instances):\n",
        "        return np.random.normal(0, 1, (instances,self.LATENT_SPACE_SIZE))\n",
        "\n",
        "    def plot_checkpoint(self,e):\n",
        "        filename = \"DCGAN/\" + str(datetime.date.today()) + \"/\" + str(e) + \".png\"\n",
        "\n",
        "        noise = self.sample_latent_space(16)\n",
        "        images = self.generator.Generator.predict(noise)\n",
        "        \n",
        "        plt.figure(figsize=(10,10))\n",
        "        for i in range(images.shape[0]):\n",
        "            plt.subplot(4, 4, i+1)\n",
        "            if self.C==1:\n",
        "                image = images[i, :, :]\n",
        "                image = np.reshape(image, [self.H,self.W])\n",
        "                image = (255*(image - np.min(image))/np.ptp(image)).astype(int)\n",
        "                plt.imshow(image,cmap='gray')\n",
        "            elif self.C==3:\n",
        "                image = images[i, :, :, :]\n",
        "                image = np.reshape(image, [self.H,self.W,self.C])\n",
        "                image = (255*(image - np.min(image))/np.ptp(image)).astype(int)\n",
        "                plt.imshow(image)\n",
        "            \n",
        "            plt.axis('off')\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(filename)\n",
        "        plt.close('all')\n",
        "        return\n",
        "\n",
        "    def plot_check_batch(self,b,images):\n",
        "        filename = \"DCGAN/batch_check_\"+str(b)+\".png\"\n",
        "        subplot_size = int(np.sqrt(images.shape[0]))\n",
        "        plt.figure(figsize=(10,10))\n",
        "        for i in range(images.shape[0]):\n",
        "            plt.subplot(subplot_size, subplot_size, i+1)\n",
        "            image = images[i, :, :, :]\n",
        "            image = np.reshape(image, [self.H,self.W,self.C])\n",
        "            plt.imshow(image)\n",
        "            plt.axis('off')\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(filename)\n",
        "        plt.close('all')\n",
        "        return\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IntquHndo8s-",
        "colab_type": "text"
      },
      "source": [
        "* l.53: 最初に`X_train_temp`に本物の画像を全部コピーしておく。\n",
        "* これまではバッチサイズ（32とか128とか）のうち半分を本物の画像の中からランダムに選択したもの、もう半分はGeneratorで生成した画像として、それらを一つにまとめた学習用データとして学習させていた。\n",
        "* 今回はバッチサイズ（128）の分の本物画像、もしくは生成画像だけを取ってきて学習を行うことを、本物の画像データがなくなるまで繰り返す。これによってパフォーマンス向上と、ネットワークが発散してしまうことを防げるらしい。\n",
        "* l.81: Generatorの学習の際に、10%だけ逆のラベル（＝偽物）を与えて学習させている。これにより収束しやすくなるらしい。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iDPKSlhvscEj",
        "colab_type": "text"
      },
      "source": [
        "# 学習実行\n",
        "\n",
        "バッチサイズとエポック数の関係については\n",
        "- [機械学習／ディープラーニングにおけるバッチサイズ、イテレーション数、エポック数の決め方](https://qiita.com/kenta1984/items/bad75a37d552510e4682)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aEIqxobMsqmj",
        "colab_type": "code",
        "outputId": "7c787127-7a0a-4dc1-df20-4b723d632ac3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "import datetime, os\n",
        "\n",
        "%cd /content\n",
        "from google.colab import drive\n",
        "drive.mount('./gdrive', force_remount=True)\n",
        "\n",
        "!mkdir -p '/content/gdrive/My Drive/Colab Notebooks/DCGAN'\n",
        "dir = '/content/gdrive/My Drive/Colab Notebooks/DCGAN/' + str(datetime.date.today())\n",
        "os.makedirs(dir, exist_ok=True)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "Mounted at ./gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9pfdpDKsIME",
        "colab_type": "code",
        "outputId": "96d56de8-a506-44e6-c97f-a35feac55124",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "%cd '/content/gdrive/My Drive/Colab Notebooks/'\n",
        "\n",
        "HEIGHT  = 64\n",
        "WIDTH   = 64\n",
        "CHANNEL = 3\n",
        "LATENT_SPACE_SIZE = 100\n",
        "EPOCHS = 100\n",
        "BATCH = 128\n",
        "CHECKPOINT = 100\n",
        "PATH = \"lsun/data/church_outdoor_train_lmdb_color.npy\"\n",
        "\n",
        "trainer = Trainer(height=HEIGHT,\\\n",
        "                 width=WIDTH,\\\n",
        "                 channels=CHANNEL,\\\n",
        "                 latent_size=LATENT_SPACE_SIZE,\\\n",
        "                 epochs =EPOCHS,\\\n",
        "                 batch=BATCH,\\\n",
        "                 checkpoint=CHECKPOINT,\\\n",
        "                 model_type='DCGAN',\\\n",
        "                 data_path=PATH)\n",
        "                 \n",
        "trainer.train()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0710 05:25:40.994905 140080986978176 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/keras/activations.py:211: UserWarning: Do not pass a layer instance (such as LeakyReLU) as the activation argument of another layer. Instead, advanced activation layers should be used just like any other layer in a model.\n",
            "  identifier=identifier.__class__.__name__))\n",
            "W0710 05:25:41.036245 140080986978176 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0710 05:25:41.044001 140080986978176 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0710 05:25:41.149880 140080986978176 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "W0710 05:25:41.179851 140080986978176 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2018: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/Colab Notebooks\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:43: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (5, 5), activation=<keras.lay..., padding=\"same\")`\n",
            "W0710 05:25:41.223943 140080986978176 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "W0710 05:25:44.369856 140080986978176 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:47: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (5, 5), activation=<keras.lay..., padding=\"same\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:51: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(3, (5, 5), activation=\"tanh\", padding=\"same\")`\n",
            "W0710 05:25:44.697921 140080986978176 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0710 05:25:44.708741 140080986978176 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "/usr/local/lib/python3.6/dist-packages/keras/engine/sequential.py:110: UserWarning: `Sequential.model` is deprecated. `Sequential` is a subclass of `Model`, you can just use your `Sequential` instance directly.\n",
            "  warnings.warn('`Sequential.model` is deprecated. '\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:35: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (5, 5), input_shape=(64, 64, 3..., activation=<keras.lay..., strides=(2, 2), padding=\"same\")`\n",
            "/usr/local/lib/python3.6/dist-packages/keras/activations.py:211: UserWarning: Do not pass a layer instance (such as LeakyReLU) as the activation argument of another layer. Instead, advanced activation layers should be used just like any other layer in a model.\n",
            "  identifier=identifier.__class__.__name__))\n",
            "W0710 05:25:45.318982 140080986978176 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 16384)             1654784   \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 16384)             65536     \n",
            "_________________________________________________________________\n",
            "reshape_1 (Reshape)          (None, 8, 8, 256)         0         \n",
            "_________________________________________________________________\n",
            "up_sampling2d_1 (UpSampling2 (None, 16, 16, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 16, 16, 128)       819328    \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 16, 16, 128)       512       \n",
            "_________________________________________________________________\n",
            "up_sampling2d_2 (UpSampling2 (None, 32, 32, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 32, 32, 64)        204864    \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 32, 32, 64)        256       \n",
            "_________________________________________________________________\n",
            "up_sampling2d_3 (UpSampling2 (None, 64, 64, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 64, 64, 3)         4803      \n",
            "=================================================================\n",
            "Total params: 2,750,083\n",
            "Trainable params: 2,716,931\n",
            "Non-trainable params: 33,152\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:38: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (5, 5), activation=<keras.lay..., strides=(2, 2), padding=\"same\")`\n",
            "/usr/local/lib/python3.6/dist-packages/keras/engine/sequential.py:110: UserWarning: `Sequential.model` is deprecated. `Sequential` is a subclass of `Model`, you can just use your `Sequential` instance directly.\n",
            "  warnings.warn('`Sequential.model` is deprecated. '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_4 (Conv2D)            (None, 32, 32, 64)        4864      \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 32, 32, 64)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 32, 32, 64)        256       \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 16, 16, 128)       204928    \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 16, 16, 128)       0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 16, 16, 128)       512       \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 32768)             0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 32769     \n",
            "=================================================================\n",
            "Total params: 243,329\n",
            "Trainable params: 242,945\n",
            "Non-trainable params: 384\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/sequential.py:110: UserWarning: `Sequential.model` is deprecated. `Sequential` is a subclass of `Model`, you can just use your `Sequential` instance directly.\n",
            "  warnings.warn('`Sequential.model` is deprecated. '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "sequential_1 (Sequential)    (None, 64, 64, 3)         2750083   \n",
            "_________________________________________________________________\n",
            "sequential_2 (Sequential)    (None, 1)                 243329    \n",
            "=================================================================\n",
            "Total params: 2,993,412\n",
            "Trainable params: 2,716,931\n",
            "Non-trainable params: 276,481\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
            "  'Discrepancy between trainable weights and collected trainable'\n",
            "/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
            "  'Discrepancy between trainable weights and collected trainable'\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Batch: 100, [Discriminator :: Loss: 0.10093285], [ Generator :: Loss: 3.3650723], 0.1575636863708496s\n",
            "Batch: 200, [Discriminator :: Loss: 0.06930032], [ Generator :: Loss: 0.058838014], 0.16363024711608887s\n",
            "Batch: 300, [Discriminator :: Loss: 0.11418487], [ Generator :: Loss: 0.036510292], 0.38782310485839844s\n",
            "Batch: 400, [Discriminator :: Loss: 0.022124382], [ Generator :: Loss: 5.0902863], 0.1645643711090088s\n",
            "Epoch: 0, [Discriminator :: Loss: 0.050763927], [ Generator :: Loss: 4.750782], 174.83482813835144s\n",
            "Batch: 100, [Discriminator :: Loss: 0.012861535], [ Generator :: Loss: 5.845931], 0.16380810737609863s\n",
            "Batch: 200, [Discriminator :: Loss: 0.095501855], [ Generator :: Loss: 4.580192], 0.5424139499664307s\n",
            "Batch: 300, [Discriminator :: Loss: 0.044095334], [ Generator :: Loss: 5.332164], 0.16562438011169434s\n",
            "Batch: 400, [Discriminator :: Loss: 0.052587934], [ Generator :: Loss: 5.133879], 0.2949178218841553s\n",
            "Batch: 500, [Discriminator :: Loss: 0.014289669], [ Generator :: Loss: 5.8774667], 0.16686487197875977s\n",
            "Epoch: 1, [Discriminator :: Loss: 0.02593643], [ Generator :: Loss: 5.7615376], 175.63850235939026s\n",
            "Batch: 100, [Discriminator :: Loss: 0.011693004], [ Generator :: Loss: 6.2208695], 0.16478991508483887s\n",
            "Batch: 200, [Discriminator :: Loss: 0.01364154], [ Generator :: Loss: 6.6021123], 0.16485834121704102s\n",
            "Batch: 300, [Discriminator :: Loss: 0.01453976], [ Generator :: Loss: 6.242996], 0.16492342948913574s\n",
            "Batch: 400, [Discriminator :: Loss: 0.048479117], [ Generator :: Loss: 5.5219045], 0.3545961380004883s\n",
            "Batch: 500, [Discriminator :: Loss: 0.010613196], [ Generator :: Loss: 3.7301788], 0.19005489349365234s\n",
            "Epoch: 2, [Discriminator :: Loss: 0.044998996], [ Generator :: Loss: 5.272543], 183.0929093360901s\n",
            "Batch: 100, [Discriminator :: Loss: 0.11356859], [ Generator :: Loss: 4.103946], 0.7425234317779541s\n",
            "Batch: 200, [Discriminator :: Loss: 0.009688372], [ Generator :: Loss: 6.7773833], 0.17287731170654297s\n",
            "Batch: 300, [Discriminator :: Loss: 0.015912268], [ Generator :: Loss: 6.9692883], 0.1655292510986328s\n",
            "Batch: 400, [Discriminator :: Loss: 0.0040237214], [ Generator :: Loss: 5.5642576], 0.2598381042480469s\n",
            "Epoch: 3, [Discriminator :: Loss: 0.914815], [ Generator :: Loss: 2.7329655], 173.24239444732666s\n",
            "Batch: 100, [Discriminator :: Loss: 0.071138516], [ Generator :: Loss: 5.0830135], 0.7130987644195557s\n",
            "Batch: 200, [Discriminator :: Loss: 0.13859257], [ Generator :: Loss: 4.061709], 0.565359354019165s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-8b3aa00e64ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mHEIGHT\u001b[0m\u001b[0;34m,\u001b[0m                 \u001b[0mwidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mWIDTH\u001b[0m\u001b[0;34m,\u001b[0m                 \u001b[0mchannels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCHANNEL\u001b[0m\u001b[0;34m,\u001b[0m                 \u001b[0mlatent_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLATENT_SPACE_SIZE\u001b[0m\u001b[0;34m,\u001b[0m                 \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m                 \u001b[0mbatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH\u001b[0m\u001b[0;34m,\u001b[0m                 \u001b[0mcheckpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCHECKPOINT\u001b[0m\u001b[0;34m,\u001b[0m                 \u001b[0mmodel_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'DCGAN'\u001b[0m\u001b[0;34m,\u001b[0m                 \u001b[0mdata_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-13-4c564e326119>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     67\u001b[0m                     \u001b[0;31m#self.plot_check_batch(b,real_images_raw)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m                     \u001b[0;31m# Delete the images used until we have none left\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m                     \u001b[0mX_train_temp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_temp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstarting_index\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstarting_index\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcount_real_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m                     \u001b[0mx_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreal_images_raw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mcount_real_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mC\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m                     \u001b[0my_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcount_real_images\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36mdelete\u001b[0;34m(arr, obj, axis)\u001b[0m\n\u001b[1;32m   4416\u001b[0m         \u001b[0mkeep\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4417\u001b[0m         \u001b[0mslobj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeep\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4418\u001b[0;31m         \u001b[0mnew\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4420\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mwrap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JExTvl7wIWFR",
        "colab_type": "text"
      },
      "source": [
        "# 学習結果\n",
        "\n",
        "## Epoch 1\n",
        "![alt text](https://drive.google.com/uc?id=1-G76knnWkU-CCnDFF8vaCskcWZFPpbMz)\n",
        "\n",
        "## Epoch 10\n",
        "![alt text](https://drive.google.com/uc?id=11l7mlpUW1SMKpo69us-fc1FZ7U34OrmP)\n",
        "\n",
        "## Epoch 20\n",
        "![alt text](https://drive.google.com/uc?id=15E4p2BeY7bzLBTZEweq4P3SkcLe-9VEQ)\n",
        "\n",
        "## Epoch 30\n",
        "![alt text](https://drive.google.com/uc?id=181o0lskvCHSCZ6de-LjNSdshAE2lQGnH)\n",
        "\n",
        "## Epoch 40\n",
        "![alt text](https://drive.google.com/uc?id=1Aa9aaSoFa9BnbIjQ0jLxh-PUYMaI0z4Q)\n",
        "\n",
        "## Epoch 50\n",
        "![alt text](https://drive.google.com/uc?id=1DEwm8NZxqALTWz83z70MQV3b29CIwLzH)\n",
        "\n",
        "## Epoch 60\n",
        "![alt text](https://drive.google.com/uc?id=1GKt6h9MYz9xV2L8YFg12Um8TCGZLQIiv)\n",
        "\n",
        "## Epoch 64\n",
        "![alt text](https://drive.google.com/uc?id=1HjSAMIo7IQwhH1KrRkUt-Vd6yHKcbnMQ)"
      ]
    }
  ]
}